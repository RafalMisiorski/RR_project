{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa77439-da6c-4105-ab2a-e77dcec06869",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data_for_modelling\u001b[39m(df, target, predictors, train_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, scaler\u001b[38;5;241m=\u001b[39m\u001b[43mStandardScaler\u001b[49m()):\n\u001b[0;32m      2\u001b[0m     \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# divide data into train and test - we do chronologically as in the case of CNN in previous analysis\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     train \u001b[38;5;241m=\u001b[39m df[:\u001b[38;5;28mint\u001b[39m(train_ratio \u001b[38;5;241m*\u001b[39m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m      5\u001b[0m     test \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;28mint\u001b[39m(train_ratio \u001b[38;5;241m*\u001b[39m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "def prepare_data_for_modelling(df, target, predictors, train_ratio=0.7, scaler=StandardScaler()):\n",
    "\n",
    "    ''' Prepare the dataset for the modelling - we do the train/test split (the first x% of observations go to train dataset, the rest to test dataset), \n",
    "        standardize the predictors and return objects ready for the modelling.\n",
    "\n",
    "    Input:\n",
    "    df (DataFrame): Dataframe with all features to be considered in model creation\n",
    "    target (string): Name of the target variable \n",
    "    train_ratio: the proportion of observations to be assigned to the train dataset (first x observations). Default - 70/30 split, as in the original work in the case of CNN. \n",
    "    scaler: the scaler used to scale the predictors. Default - standard scaler used in the original solution.\n",
    "\n",
    "    Output:\n",
    "    Objects ready to be used in the modelling (X/y train/test).\n",
    "\n",
    "    Notes:\n",
    "    We use the chronological assignment to the train/test datasets, not the random sampling, as we deal with time series data.\n",
    "    '''\n",
    "    \n",
    "    # divide data into train and test - we do chronologically as in the case of CNN in previous analysis\n",
    "    train = df[:int(train_ratio * df.shape[0])]\n",
    "    test = df[int(train_ratio * df.shape[0]):]\n",
    "    \n",
    "    # scale the predictors - train and test separately!\n",
    "    X_train = scaler.fit_transform(train[predictors])\n",
    "    X_test = scaler.fit_transform(test[predictors])\n",
    "\n",
    "    # assign the target to separate objects - according to standards used in Python DS\n",
    "    y_train = train[target]\n",
    "    y_test = test[target]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d4a63-321d-4536-a351-9475b260ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_evaluate( X_train, y_train, X_test, y_test, \n",
    "                           eval_metric = mean_absolute_percentage_error,\n",
    "                           model=XGBRegressor, \n",
    "                           model_params={'objective' : \"reg:squarederror\",\n",
    "                                         'reg_lambda' : 0.8,\n",
    "                                         'alpha' :0.9,\n",
    "                                         'n_estimators' : 100,\n",
    "                                         'colsample_bytree' : 0.6,\n",
    "                                         'gamma':0.85 , \n",
    "                                         'eta' : 0.036,\n",
    "                                         'max_depth' : 25, \n",
    "                                         'min_child_weight' : 1, \n",
    "                                         'subsample':0.8, \n",
    "                                         'num_parallel_tree' : 4, \n",
    "                                         #'early_stopping_rounds' : 50,\n",
    "                                         'random_state' : 123}):\n",
    "\n",
    "    ''' Create and evaluate a chosen ML model. \n",
    "\n",
    "    Input:\n",
    "    X_train, y_train, X_test, y_test (DataFrame/Matrix/Array): objects used in the modelling as the input (calculated using e.g. prepare_data_for_modelling() function).\n",
    "    eval_metric: evaluation metric used for the model evaluation. Default - mean absolute percentage error as in the original work.\n",
    "    model: the model to be calculated. Default - XGBoost Regressor, as in the original work (the first model).\n",
    "    model_params: a dictionary containing information about the hyperparameters of the model to be trained. The default hyperparameters set as in the XGBoost in the original work\n",
    "                  (apart from the early_stopping_rounds - we exclude it to make the function more universal).\n",
    "    \n",
    "    Output:\n",
    "    No exact output, we just print the information about the evaluation metric value for the train and test dataset.\n",
    "    '''\n",
    "                                             \n",
    "    model_to_fit = model(**model_params) # attach the hyperaparameters for our model\n",
    "    \n",
    "    model_to_fit.fit(X_train, y_train) # fit/train the chosen model\n",
    "    \n",
    "    # Make predictions on train and test data\n",
    "    predictions_train = model_to_fit.predict(X_train) \n",
    "    predictions_test = model_to_fit.predict(X_test)\n",
    "    \n",
    "    # Calculate the evaluation metric value on train and test data\n",
    "    eval_train = eval_metric(y_train, predictions_train)\n",
    "    eval_test = eval_metric(y_test, predictions_test)\n",
    "\n",
    "    # print the information about the evaluation metric value for train/test\n",
    "    print(\"Model evaluation: \\n Result for train data: {}. \\n Result for test data: {}.\".format(round(eval_train,3), round(eval_test,3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
